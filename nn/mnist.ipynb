{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as tf\n",
    "\n",
    "path = \"mnist\"\n",
    "\n",
    "trans = tf.Compose([tf.ToTensor(), torch.flatten])\n",
    "\n",
    "train_ds = MNIST(path, train=True, download=True, transform=trans)\n",
    "test_ds = MNIST(path, train=False, download=True, transform=trans)\n",
    "\n",
    "train_ds, val_ds = data.random_split(train_ds, [0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, layer_sizes, act=nn.ReLU()) -> None:\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.l1 = nn.Linear(layer_sizes[0], layer_sizes[1])\n",
    "        self.l2 = nn.Linear(layer_sizes[1], layer_sizes[2])\n",
    "        self.output = nn.Linear(layer_sizes[2], layer_sizes[3])\n",
    "        self.act = act\n",
    "    \n",
    "    def forward(self, x):\n",
    "        v = self.act(self.l1(x))\n",
    "        v = self.act(self.l2(v))\n",
    "        v = self.act(self.output(v))\n",
    "\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# model = Net((28 * 28, 256, 128, 10)).to(device)\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(28 * 28, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 10)\n",
    ").to(device)\n",
    "cost = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "val_loss = []\n",
    "val_acc = []\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS), 'Epoch'):\n",
    "    epoch_loss = []\n",
    "    epoch_acc = []\n",
    "\n",
    "    train_loader = data.DataLoader(train_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "    for x, y in train_loader:\n",
    "        model.train()\n",
    "        y = y.to(device)\n",
    "\n",
    "        # Compute prediction and loss\n",
    "        pred = model(x.to(device))\n",
    "\n",
    "        loss = cost(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        acc = (pred.detach().squeeze().argmax(dim=1) == y).float().mean()\n",
    "    \n",
    "        epoch_loss.append(loss.detach())\n",
    "        epoch_acc.append(acc)\n",
    "    \n",
    "    val_loader = data.DataLoader(val_ds, batch_size=len(val_ds))\n",
    "    x, y = next(iter(val_loader))\n",
    "    y = y.to(device)\n",
    "\n",
    "    pred = model(x.to(device))\n",
    "\n",
    "    loss = cost(pred, y).detach()\n",
    "    acc = (pred.detach().squeeze().argmax(dim=1) == y).float().mean()\n",
    "\n",
    "    val_loss.append(loss.cpu())\n",
    "    val_acc.append(acc.cpu())\n",
    "\n",
    "    train_loss.append(torch.tensor(epoch_loss).mean())\n",
    "    train_acc.append(torch.tensor(epoch_acc).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "test_loader = data.DataLoader(test_ds, batch_size=len(test_ds))\n",
    "x, y = next(iter(test_loader))\n",
    "\n",
    "output = model(x.to(device)).detach().squeeze()\n",
    "\n",
    "acc = (output.argmax(dim=1) == y.to(device)).float().mean()\n",
    "print('test accuracy =', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(train_loss, label=\"Training\")\n",
    "plt.plot(val_loss, label=\"Validation\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(train_acc, label=\"Training\")\n",
    "plt.plot(val_acc, label=\"Validation\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 24 2022, 14:07:00) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "04a52977b9b0128aeceb5fa2243ef17bfbe5750e2fde3784d8ec4b1c8903c208"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
