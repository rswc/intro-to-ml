{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [14, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Func:\n",
    "    def __init__(self, params) -> None:\n",
    "        self.params = np.array(params, dtype=np.float64)\n",
    "\n",
    "    def grad(self, X):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "class LinearMSE(Func):\n",
    "    def __call__(self, X, Y):\n",
    "        return np.mean(np.square(Y - self.pred(X))) / 2\n",
    "\n",
    "    def pred(self, X):\n",
    "        return self.params[0] + self.params[1] * X\n",
    "\n",
    "    def grad(self, X, Y):\n",
    "        X = np.reshape(X, (1, -1))\n",
    "        err = self.pred(X) - Y\n",
    "        \n",
    "        tt = np.concatenate([err, err * X], axis=0)\n",
    "\n",
    "        return np.mean(tt, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(func: LinearMSE, X, Y, num_epochs: int, learning_rate: float):\n",
    "    params_history = [func.params.copy()]\n",
    "    grad_history = []\n",
    "    loss_history = []\n",
    "\n",
    "    for _ in tqdm(range(num_epochs)):\n",
    "        grad = func.grad(X, Y)\n",
    "\n",
    "        func.params -= grad * learning_rate\n",
    "\n",
    "        params_history.append(func.params.copy())\n",
    "        grad_history.append(grad)\n",
    "        loss_history.append(func(X, Y))\n",
    "    \n",
    "    return np.array(params_history), np.array(grad_history), np.array(loss_history)\n",
    "\n",
    "def fit_sgd(func: LinearMSE, X, Y, batch_size: float, num_epochs: int, learning_rate: float):\n",
    "    __X = X.copy()\n",
    "    __Y = Y.copy()\n",
    "    num_samples = X.shape[0]\n",
    "\n",
    "    params_history = [func.params.copy()]\n",
    "    grad_history = []\n",
    "    loss_history = []\n",
    "\n",
    "    for _ in tqdm(range(num_epochs)):\n",
    "        perm = np.random.permutation(num_samples)\n",
    "        __X, __Y = __X[perm], __Y[perm]\n",
    "\n",
    "        for batch_start in range(0, num_samples, batch_size):\n",
    "            x = __X[batch_start:batch_start + batch_size]\n",
    "            y = __Y[batch_start:batch_start + batch_size]\n",
    "\n",
    "            grad = func.grad(x, y)\n",
    "\n",
    "            func.params -= grad * learning_rate\n",
    "\n",
    "            params_history.append(func.params.copy())\n",
    "            grad_history.append(grad)\n",
    "            loss_history.append(func(x, y))\n",
    "    \n",
    "    return np.array(params_history), np.array(grad_history), np.array(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_START = 0\n",
    "WINDOW_END = 5\n",
    "WINDOW_COUNT = 100\n",
    "\n",
    "DATA_B_0 = 8\n",
    "DATA_B_1 = -4\n",
    "\n",
    "VIZ_PARAM_MIN = -10\n",
    "VIZ_PARAM_MAX = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.linspace(WINDOW_START, WINDOW_END, WINDOW_COUNT)\n",
    "\n",
    "Y = DATA_B_1 * X + DATA_B_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = LinearMSE([-7, 1])\n",
    "\n",
    "\n",
    "ph, gh, lh = fit(func, X, Y, num_epochs=100, learning_rate=1e-1)\n",
    "# ph, gh, lh = fit_sgd(func, X, Y, batch_size=10, num_epochs=10, learning_rate=1e-1)\n",
    "\n",
    "f_series = func.pred(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_len = ph.shape[0] - 1\n",
    "for pi in np.linspace(0, ph_len, 7):\n",
    "    print(f'Line #{int(pi)} params:', ph[int(pi)])\n",
    "    plt.plot(X, LinearMSE(ph[int(pi)]).pred(X), 'b', alpha=pi/ph_len)\n",
    "\n",
    "plt.plot(X, Y, 'r--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(221)\n",
    "plt.plot(ph[:, 0])\n",
    "plt.title('Param 0')\n",
    "plt.subplot(222)\n",
    "plt.plot(gh[:, 0])\n",
    "plt.title('Gradient 0')\n",
    "plt.subplot(223)\n",
    "plt.plot(ph[:, 1])\n",
    "plt.title('Param 1')\n",
    "plt.subplot(224)\n",
    "plt.plot(gh[:, 1])\n",
    "plt.title('Gradient 1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lh)\n",
    "plt.title('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0s = np.linspace(VIZ_PARAM_MIN, VIZ_PARAM_MAX, 200)\n",
    "p1s = np.linspace(VIZ_PARAM_MIN, VIZ_PARAM_MAX, 200)\n",
    "\n",
    "ps = itertools.product(p0s, p1s)\n",
    "\n",
    "f = [[LinearMSE([p0, p1])(X, Y) for p1 in p1s] for p0 in p0s]\n",
    "\n",
    "plt.imshow(f, extent=[VIZ_PARAM_MIN, VIZ_PARAM_MAX, VIZ_PARAM_MIN, VIZ_PARAM_MAX])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 24 2022, 14:07:00) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "04a52977b9b0128aeceb5fa2243ef17bfbe5750e2fde3784d8ec4b1c8903c208"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
